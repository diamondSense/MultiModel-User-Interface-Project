{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp \n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Give absolute path of the model\n",
    "model_path = 'E:/University/Spring 2025/Multimodal User Interfaces/Project/MultiModel-User-Interface-Project/test/efficientdet_lite0.tflite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LiveStream Detection using Basic MediaPipe Model (Test 1)\n",
    "\n",
    "1. Works fine but is not very accurate (have to check with other objects also). \n",
    "2. Is fast compared to both EfficientDet-Lite2 Model MobileNetV2 Model \n",
    "\n",
    "### OVERALL: Faster, accurate performance compared to all 3 models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe components\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "DetectionResult = mp.tasks.components.containers.DetectionResult\n",
    "ObjectDetector = mp.tasks.vision.ObjectDetector\n",
    "ObjectDetectorOptions = mp.tasks.vision.ObjectDetectorOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "#NOTE: Load the model (Give absolute path of the model)\n",
    "model_path = 'E:/University/Spring 2025/Multimodal User Interfaces/Project/MultiModel-User-Interface-Project/test/efficientdet_lite0.tflite'\n",
    "\n",
    "# Initialize global detection result\n",
    "detection_result = None\n",
    "\n",
    "# Define callback function to store detection results\n",
    "def print_results(result: DetectionResult, output_image: mp.Image, timestamp_ms: int): # type: ignore\n",
    "    global detection_result\n",
    "    detection_result = result  # Store the latest detection result\n",
    "\n",
    "# Define object detection options\n",
    "options = ObjectDetectorOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.LIVE_STREAM,\n",
    "    max_results=5,\n",
    "    score_threshold=0.3,\n",
    "    result_callback=print_results\n",
    ")\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)  # Change index if needed\n",
    "\n",
    "with ObjectDetector.create_from_options(options) as detector:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "        \n",
    "        # Convert the frame to RGB format\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Create an mp.Image object\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "\n",
    "        # Get the timestamp\n",
    "        frame_timestamp_ms = int(cap.get(cv2.CAP_PROP_POS_MSEC))\n",
    "\n",
    "        # Run detection asynchronously\n",
    "        detector.detect_async(mp_image, frame_timestamp_ms)\n",
    "\n",
    "        # Draw detections if available\n",
    "        if detection_result and detection_result.detections:\n",
    "            for detection in detection_result.detections:\n",
    "                bbox = detection.bounding_box\n",
    "                x, y, w, h = int(bbox.origin_x), int(bbox.origin_y), int(bbox.width), int(bbox.height)\n",
    "                \n",
    "                # Draw rectangle around detected object\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                \n",
    "                # Get the label and confidence score\n",
    "                category = detection.categories[0]\n",
    "                label = category.category_name\n",
    "                score = category.score\n",
    "                \n",
    "                # Put label text\n",
    "                text = f\"{label} ({score:.2f})\"\n",
    "                cv2.putText(frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow(\"EfficientDet-Lite0 model\", frame)\n",
    "\n",
    "        # Press 'q' to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EfficientDet-Lite2 model Advance (Test 2)\n",
    "\n",
    "1. Super Slow not detecting objects fast takes too much time\n",
    "2. The frame rate of the screen is also not smooth lags a lot \n",
    "### OVERALL: Poor Perfromance than the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe components\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "DetectionResult = mp.tasks.components.containers.DetectionResult\n",
    "ObjectDetector = mp.tasks.vision.ObjectDetector\n",
    "ObjectDetectorOptions = mp.tasks.vision.ObjectDetectorOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "#NOTE: Load the model (Give absolute path of the model)\n",
    "model_path = 'E:/University/Spring 2025/Multimodal User Interfaces/Project/MultiModel-User-Interface-Project/test/efficientdet_lite2.tflite'\n",
    "\n",
    "# Initialize global detection result\n",
    "detection_result = None\n",
    "\n",
    "# Define callback function to store detection results\n",
    "def print_results(result: DetectionResult, output_image: mp.Image, timestamp_ms: int): # type: ignore\n",
    "    global detection_result\n",
    "    detection_result = result  # Store the latest detection result\n",
    "\n",
    "# Define object detection options\n",
    "options = ObjectDetectorOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.LIVE_STREAM,\n",
    "    max_results=5,\n",
    "    score_threshold=0.3,\n",
    "    result_callback=print_results\n",
    ")\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)  # Change index if needed\n",
    "\n",
    "with ObjectDetector.create_from_options(options) as detector:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "        \n",
    "        # Convert the frame to RGB format\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Create an mp.Image object\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "\n",
    "        # Get the timestamp\n",
    "        frame_timestamp_ms = int(cap.get(cv2.CAP_PROP_POS_MSEC))\n",
    "\n",
    "        # Run detection asynchronously\n",
    "        detector.detect_async(mp_image, frame_timestamp_ms)\n",
    "\n",
    "        # Draw detections if available\n",
    "        if detection_result and detection_result.detections:\n",
    "            for detection in detection_result.detections:\n",
    "                bbox = detection.bounding_box\n",
    "                x, y, w, h = int(bbox.origin_x), int(bbox.origin_y), int(bbox.width), int(bbox.height)\n",
    "                \n",
    "                # Draw rectangle around detected object\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                \n",
    "                # Get the label and confidence score\n",
    "                category = detection.categories[0]\n",
    "                label = category.category_name\n",
    "                score = category.score\n",
    "                \n",
    "                # Put label text\n",
    "                text = f\"{label} ({score:.2f})\"\n",
    "                cv2.putText(frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow(\" EfficientDet-Lite2 model\", frame)\n",
    "\n",
    "        # Press 'q' to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SSD MobileNetV2 model (Test 3)\n",
    "\n",
    "1. Better than Lite2 model\n",
    "2. A little slow than Lite0 model and less accurate also \n",
    "3. It is suppose to be better than Lite0 model but have to check qith other objects aswell \n",
    "\n",
    "OVERALL: Better than Lite2 model but less accurate than Lite0 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe components\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "DetectionResult = mp.tasks.components.containers.DetectionResult\n",
    "ObjectDetector = mp.tasks.vision.ObjectDetector\n",
    "ObjectDetectorOptions = mp.tasks.vision.ObjectDetectorOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "#NOTE: Load the model (Give absolute path of the model)\n",
    "model_path = 'E:/University/Spring 2025/Multimodal User Interfaces/Project/MultiModel-User-Interface-Project/test/ssd_mobilenet_v2.tflite'\n",
    "\n",
    "# Initialize global detection result\n",
    "detection_result = None\n",
    "\n",
    "# Define callback function to store detection results\n",
    "def print_results(result: DetectionResult, output_image: mp.Image, timestamp_ms: int): # type: ignore\n",
    "    global detection_result\n",
    "    detection_result = result  # Store the latest detection result\n",
    "\n",
    "# Define object detection options\n",
    "options = ObjectDetectorOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.LIVE_STREAM,\n",
    "    max_results=5,\n",
    "    score_threshold=0.3,\n",
    "    result_callback=print_results\n",
    ")\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)  # Change index if needed\n",
    "\n",
    "with ObjectDetector.create_from_options(options) as detector:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "        \n",
    "        # Convert the frame to RGB format\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Create an mp.Image object\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "\n",
    "        # Get the timestamp\n",
    "        frame_timestamp_ms = int(cap.get(cv2.CAP_PROP_POS_MSEC))\n",
    "\n",
    "        # Run detection asynchronously\n",
    "        detector.detect_async(mp_image, frame_timestamp_ms)\n",
    "\n",
    "        # Draw detections if available\n",
    "        if detection_result and detection_result.detections:\n",
    "            for detection in detection_result.detections:\n",
    "                bbox = detection.bounding_box\n",
    "                x, y, w, h = int(bbox.origin_x), int(bbox.origin_y), int(bbox.width), int(bbox.height)\n",
    "                \n",
    "                # Draw rectangle around detected object\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                \n",
    "                # Get the label and confidence score\n",
    "                category = detection.categories[0]\n",
    "                label = category.category_name\n",
    "                score = category.score\n",
    "                \n",
    "                # Put label text\n",
    "                text = f\"{label} ({score:.2f})\"\n",
    "                cv2.putText(frame, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow(\"SSD MobileNetV2 model\", frame)\n",
    "\n",
    "        # Press 'q' to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
